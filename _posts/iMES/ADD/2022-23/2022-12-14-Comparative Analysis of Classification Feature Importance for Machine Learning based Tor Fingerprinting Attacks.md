---
title: "기계학습 기반 토르 핑거프린팅 공격 기술의 분류 feature 중요도 비교 분석"
author: [Joe2357, j.Bang, j17.lee]
categories: [1. iMES, Agency for Defense Development (ADD) / 2022-23]
tags: [Agency for Defense Development (ADD) / 2022-23, Publication]
description: "- Published in 대한전자공학회 전자공학회논문지 (Vol.60 No.1)"
math: true
---



## 요약

본 논문은 웹사이트 핑거프린팅에 대한 선행 연구 조사와 웹사이트 핑거프린팅 기법 사용 시 웹사이트 분류에 기여하는 feature 중요도를 정량적으로 분석한다. 이를 위해, 기존 연구에서 주로 사용하는 특징들을 트리 기반 앙상블 알고리즘 학습에 사용하며, 해당 feature 요소들이 웹사이트 분류에 기여하는 정도에 따른 중요도 및 상관관계를 실험적으로 분석한다. 또한, 해당 feature들의 조합에 따른 연산시간도 분석함으로써 핑거프린팅 공격에 효과적으로 활용될 수 있는 중요 feature 조합에 대해 제시한다.



## 서론

- 토르 네트워크 ( Tor Network ) : 다양한 릴레이 노드를 활용해 암호화를 진행하여 익명성을 보장
  - 최근 인공지능 기술의 발달과 함께, 토르 네트워크의 익명성을 해치려는 시도가 계속해서 연구됨
    - **핑거프린팅 공격 방법** : 기계학습을 활용하여 웹사이트별 트래픽의 특징을 추출하고, 이를 통해 특정 웹사이트를 식별하는 방법
  - 기계학습을 도입한 이후 핑거프린팅 공격을 위한 다양한 feature들이 고려되기 시작
    - But 이전 연구들에서는 각 feature들의 조합에 대한 <u>정량적인 분석이 미흡</u>하고, 이에 따라 <u>적절한 feature의 조합을 제시할 수 있는 연구가 부족</u>했다 평가
- 본 논문에서는 핑거프린팅 공격을 효과적으로 하기 위한 토르 네트워크에서의 핑거프린팅 공격 방법의 기술을 다룸
  - 네트워크 공격자가 트래픽의 패턴을 분석함으로써 토르 네트워크의 익명성을 공격하는 것에 초점
    - 핑거프린팅 공격 시 기계학습에서 활용되는 분류 feature들 (패킷의 통신 방향, 시간 정보 등) 에 대한 분석
    - 해당 feature들을 통해 세분화된 특징들 (통신에 사용한 패킷 통계 정보, 시간 간격 통계 정보 등) 을 도출
    - 도출된 분류 특징들이 핑거프린팅 공격에 미치는 기여도를 실험적으로 분석하기 위해 트리 기반 머신러닝의 앙상블 기법을 도입하여 각 feature들의 중요도 및 상관관계를 구함
    - 해당 feature들의 조합에 따른 연산시간도를 분석하여 핑거프린팅 공격에 효과적으로 활용될 수 있는 중요 feature 조합에 대해 제시



## 본론

### 토르 브라우저

- 어니언 라우팅(onion routing)을 이용하여 사용자가 출발지와 목적지의 IP주소를 노출하지 않고 인터넷 서비스를 이용할 수 있도록 설계된 **익명 오버레이 네트워크**
  - 어니언 라우팅 : 인터넷상의 여러 장소에 트랜잭션을 분산시켜 네트워크 트래픽 도청 위험을 줄여주는 방법
  - 토르에서는 패킷이 목적지로 직접 이동하지 않고, 랜덤한 경로에 존재하는 여러 릴레이 노드를 통하여 전달됨
    - 각각의 노드들은 불특정하게 회로에 참여하고, IP주소의 암호화를 통해 사용자들의 익명성을 보장



### 최신기술 동향 조사

- 핑거프린팅 공격 기법에 대한 조사 분석 진행

  ![fig 1](https://github.com/Joe2357/Joe2357.github.io/blob/main/assets/img/post/add/2022-12-14-KCIPaper/fig1.png?raw=true)

  - <u>사용자와 토르 네트워크의 입구 노드 사이는 암호화되지 않는다</u>는 토르의 취약점을 통해 네트워크 사용자의 **트래픽을 도청**하여 공격하는 기술
  - 패킷이 암호화되어 전송된다고 하더라도 <u>패킷의 흐름 패턴을 분석</u>하여 특정 웹사이트에 접속하는 **사용자를 파악**하는 것이 가능
  - 최근에는 딥러닝과 기계학습 등의 인공지능 기술을 접목하여 트래픽 데이터로부터 웹사이트에서의 feature를 추출하는 방법으로 연구를 진행

- 대부분의 선행 연구에서는 패킷 흐름 데이터에서 **패킷의 방향**과 **시간 정보**를 주요 feature로 선택
  - 패킷의 길이를 주요 특징으로 선택해야 한다는 의견도 있지만 패킷의 길이를 5000으로 고정하여 사용하며 패킷의 길이가 중요하지 않다고 지적하는 연구도 있음
  - But 기존 선행 연구에서는 각 주요 feature들이 서로에게 어떠한 영향을 미치는지 알 수 없으며, 본 연구에서는 이에 착안하여 각 feature들의 중요도에 대한 실험적 분석을 진행

| 공격 기술 |      중요 feature      |      입력 feature      | 정확도 |
| :-------: | :--------------------: | :--------------------: | :----: |
|   SDAE    |      패킷 방향성       |      패킷 방향성       | 92.3%  |
|    TF     |      패킷 방향성       |      패킷 방향성       | 95.0%  |
|   DNNWF   |      패킷 방향성       |   웹사이트 예시 정보   | 96.2%  |
|    DF     |      패킷 방향성       |      패킷 방향성       | 98.3%  |
|  Tik-Tok  | 패킷 방향성, 시간 정보 | 패킷 방향성, 시간 정보 | 98.4%  |
|   snWF    |      데이터 원본       |       패킷 정보        | 98.8%  |

- snWF의 경우 데이터를 가공하지 않은 상태로 앙상블 기법을 이용하여 인공지능이 스스로 중요하다고 생각하는 feature를 선택



### 앙상블 알고리즘

- 일반화와 강건성을 향상시키기 위해 여러 모델의 예측값을 결합하는 방법
  - 하나의 복잡한 머신러닝 모델을 사용하는 대신, **단순한 모델 여러 개를 조합**하여 더 정확한 예측을 달성하는 기계학습 방법
    - 평균 방법 : 여러 개의 추정값을 독립적으로 구한 뒤 평균을 취하는 방법
      - 결합 추정값은 분산이 줄어들기 때문에 단일 추정값보다 좋은 성능을 보임
    - 부스팅 방법 : 순차적으로 모델을 생성하고 이전 단계의 학습결과에서 잘못 예측된 샘플에 가중치를 부여하는 방법
      - 결합된 모델의 편향을 감소시키는 효과가 있음
- 본 논문에서 웹사이트 분류를 위해 앙상블 알고리즘의 평균 방법인 Decision Tree 알고리즘, Random Forest 알고리즘과 Extra Tree 알고리즘을 사용하고, 부스팅 방법으로 XGBoost 알고리즘을 사용



## 실험

- Wang 데이터셋으로부터 주요 feature들을 전처리한 후, 앙상블 알고리즘을 통해 웹사이트 분류 학습을 진행

- 모델 파라미터를 정하기 위해 GridSearch 이용

  |            사용 모델            | 정확도 |
  | :-----------------------------: | :----: |
  |       DT (Decision Tree)        | 75.4%  |
  |       RF (Random Forest)        | 86.4%  |
  |         ET (Extra Tree)         | 89.2%  |
  | XGB (eXtreme Gradient Boosting) | 88.8%  |

  - 분류 정확도가 가장 높은 **Extra Tree** 알고리즘으로 이후 학습을 진행할 것

- 사용된 feature들 중에서 중요한 feature를 선택 // 모델 학습 시간과 정확도 사이의 균형을 맞추기 위함

  - 특정 feature가 **트리를 분할하는데 얼마나 기여하였는가**를 측정하여 결정
  - purity (순수도) : 엔트로피를 활용한 information gain으로 계산하고, feature의 순수도 값이 클수록 높은 중요도로 반영

- 실험을 통해 도출된 중요 feature

  - 데이터 : 특정 작업을 위해 웹사이트에 접속하는 하나의 flow

  | 중요도 순위 |              feature 명               |
  | :---------: | :-----------------------------------: |
  |      1      |          수신된 패킷의 개수           |
  |      2      |           전체 패킷의 개수            |
  |      3      |          송신된 패킷의 개수           |
  |      4      |           송신 패킷의 비율            |
  |      5      |           수신 패킷의 비율            |
  |      6      |  초기 30개에 수신된 패킷의 수신 비율  |
  |      7      |  초기 30개에 수신된 패킷의 전체 비율  |
  |      8      |          송신 버스트 최댓값           |
  |      9      |  초기 30개에 송신된 패킷의 전체 비율  |
  |     10      |  초기 30개에 송신된 패킷의 송신 비율  |
  |     11      |  마지막 5초 동안 발생한 패킷의 개수   |
  |     12      |         송신 버스트 표준편차          |
  |     13      |           송신 버스트 평균            |
  |     14      |           송신 버스트 개수            |
  |     15      |           수신 버스트 개수            |
  |     16      |   초기 5초 수신 버스트의 패킷 개수    |
  |     17      |   초기 5초 송신 버스트의 패킷 개수    |
  |     18      |        초당 수신된 패킷의 개수        |
  |     19      | 초기 5초 동안 수신된 패킷의 전체 비율 |
  |     20      | 초기 5초 동안 송신된 패킷의 전체 비율 |

- feature를 얼마나 사용했는가에 따른 모델 학습시간과 정확도

  |           |      5개      |     10개      |     20개      |
  | :-------: | :-----------: | :-----------: | :-----------: |
  | 학습 시간 | 0.855 ± 0.007 | 0.872 ± 0.006 | 0.989 ± 0.009 |
  |  정확도   | 0.660 ± 0.040 | 0.810 ± 0.024 | 0.871 ± 0.023 |

  - feature를 사용할수록 학습시간이 약간 증가하지만, 정확도가 크게 상향되는 것을 볼 수 있음
    - 전체 feature를 사용한 정확도와 거의 유사한 모습을 보임
    - => **소수 중요한 feature만을 사용하여도 학습시간은 줄이면서 높은 정확도를 달성할 수 있다**

- feature 중요도 값을 가지고 전체 feature 중 상위 몇 개까지 feature를 선택할지를 결정하는 그리디(greedy)한 휴리스틱 알고리즘을 제안

  ```pseudocode
  Input: All preprocessed features F, required accuracy θacc
    
   1| Sort F by rank using feature_importance_
   2| Fselect is top 1 feature in F
   3| while do
   4|     Calculare ACC using Fselect
   5|     if θacc > ACC then
   6|         Add next rank feature in F to Fselect
   7|     else
   8|         return Fselect
   9|     end if
  10| end while
  ```

  - feature 중요도 값을 이용하여 전체 feature들 중 상위 몇개까지 feature를 선택하여 사용할 것인지 **greedy한 heuristic 알고리즘** 제안
    - 모델 학습에 사용된 전체 feature ($F$)들을 feature 중요도의 순위 순으로 정렬
    - 첫 번째 feature를 $F_{select}$에 추가
    - $F_{select}$에 있는 feature를 가지고 정확도 ($ACC$)를 계산
    - 요구되는 정확도 threshold ($\theta_{acc}$)값과 비교
      - 계산한 정확도 값이 threshold 값보다 작다면 $F_{select}$에 다음 순위 feature를 추가
      - 계산한 정확도 값이 threshold 값보다 크거나 같다면 $F_{select}$를 반환
    - => 학습 속도와 정확도의 균형을 맞출 수 있는 feature set을 선택할 수 있도록 함

- 상위 10개의 feature들간의 상관관계를 나타낸 표 참고

  - **송신 버스트 개수 최댓값 feature**가 토르 웹사이트 분류와 상관관계값이 가장 높음 (0.054)
  - feature를 선택함에 있어 위 표를 활용할 수 있을 것이라 기대



## 결론

- 토르 네트워크의 익명성을 해치는 방법인 핑거프린팅에 대한 선행 연구를 정리
  - 선행 연구에서 feature 중요도에 대한 정량적 분석과 feature들의 상관관계가 미흡하다는 사실을 발견
  - 실험적으로 feature들의 분석 진행
    - 토르 네트워크 트래픽 데이터셋에서 중요 특징들을 전처리
    - 웹사이트를 분류하는데 크게 기여하는 특징들을 정량화하고 상관관계를 분석
  - 웹사이트 분류에 기여하는 상위 feature들로 재학습했을 때의 학습 속도와 정확도를 비교하여 중요 feature들의 조합을 제시

